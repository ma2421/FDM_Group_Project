# -*- coding: utf-8 -*-
"""Email_Spam_Detection_Bigram.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19jsLSZANKDhDeMGvWp7KVqMOyHMmJumK
"""

!pip install wordfreq
!pip install emoji --quiet
!pip install joblib scikit-learn matplotlib seaborn
# Download stopwords if not already
import nltk
import chardet
import pandas as pd
import gdown
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
import string
from bs4 import BeautifulSoup
from nltk.corpus import stopwords
import numpy as np
import zipfile
import emoji
import joblib
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score, precision_score, recall_score, accuracy_score, classification_report
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler, FunctionTransformer
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.pipeline import Pipeline, FeatureUnion
from scipy.sparse import hstack
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/FDM_Project

pd.set_option('display.max_colwidth', 200)

trec_data = pd.read_csv('TREC_Dataset.csv')
trec_data['source'] = 'trec'
trec_data = trec_data[['source','message', 'label']]


enron_data = pd.read_csv('Enron_Spam_Dataset.csv')
enron_data['Spam/Ham'] = enron_data['Spam/Ham'].map({'spam': 1, 'ham': 0})
enron_data['source'] = 'enron'
enron_data.rename(columns={'Spam/Ham': 'label'}, inplace=True)
enron_data.rename(columns={'Message': 'message'}, inplace=True)
enron_data = enron_data[['source','message', 'label']]

spamAssassin_data = pd.read_parquet('Spam_Assassin_Dataset.parquet')
spamAssassin_data['label'] = spamAssassin_data['group'].map({'easy_ham': 0, 'easy_ham_2': 0, 'hard_ham':0, 'spam' :1, 'spam_2':1})
spamAssassin_data['source'] = 'spamAssassin'
spamAssassin_data.rename(columns={'text': 'message'}, inplace=True)
spamAssassin_data = spamAssassin_data[['source','message', 'label']]

print(trec_data.shape)
print(enron_data.shape)
print(spamAssassin_data.shape)

print(trec_data.label.value_counts())
print(enron_data.label.value_counts())
print(spamAssassin_data.label.value_counts())

# extract important features from emails
from wordfreq import word_frequency

def is_real_english_word(word, lang='en', threshold=1e-16):
    return (
        word_frequency(word.lower(), lang) > threshold
        # or word.lower() in custom_vocab
    )

def is_real_french_word(word, lang='fr', threshold=1e-16):
    return (
        word_frequency(word.lower(), lang) > threshold
        # or word.lower() in custom_vocab
    )

def extract_handcrafted_features(email_text):
    """
    Extract handcrafted features for spam detection.
    """
    features = {}

    # All caps words
    features['num_all_caps'] = len(re.findall(r'\b[A-Z]{2,}\b', email_text))

    # Obfuscated words (ex: fr33, c@sh, etc.)
    suspicious = set()
    obfuscated_matches = re.findall(r'\b[a-zA-Z0-9][@$0-9][a-zA-Z0-9]\b', email_text) # detect obfuscate words like fr33, v1agra, c@sh
    suspicious.update(obfuscated_matches)
    clean_text = email_text
    for word in obfuscated_matches:
        clean_text = clean_text.replace(word, '')

    # Step 3: Tokenize clean text into normal words
    tokens = re.findall(r'\b[a-zA-Z]{3,}\b', clean_text)
    for word in tokens:
        if not is_real_english_word(word) and not is_real_french_word(word):
            suspicious.add(word) # detect misspelled words or gibberish words or non-english words like fre, offrr, monay, fjksd, asd123x
    features['num_obfuscated_words'] = len(suspicious)

    # Currency mentions
    features['num_currency_mentions'] = len(re.findall(r'[\$€£₹¥]|USD|EUR|GBP|INR|YEN', email_text, re.IGNORECASE))

    # Emoji count
    features['num_emojis'] = len([c for c in email_text if c in emoji.EMOJI_DATA])

    # Phone number mentions
    features['num_phone_numbers'] = len(re.findall(r'\b\d{3}[-.\s]?\d{3}[-.\s]?\d{4}\b', email_text))

    # URL mentions
    features['num_urls'] = len(re.findall(r'https?://\S+|ftp://\S+|www\.\S+', email_text))

    return features


# Function to clean the raw email to embedding-friendly emails
def prepare_clean_text_for_embedding(email_text):
    """
    Clean the email while preserving contextual signals via special tokens.
    """
    # Convert to lowercase
    text = email_text.lower()

    text = re.sub(r'\\n+', ' ', text)

    # Replace URLs and emails
    text = re.sub(r'https?://\S+|ftp://\S+|www\.\S+', ' <URL> ', text)
    text = re.sub(r'\b[\w\.-]+@[\w\.-]+\.\w+\b', ' <EMAIL> ', text)

    text = re.sub(r'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}[+-]\d{2}:\d{2}', ' <DATE> ', text)

    # Replace phone numbers
    text = re.sub(r'\b\d{3}[-.\s]?\d{3}[-.\s]?\d{4}\b', ' <PHONE> ', text)

    # Remove phone numbers and extensions
    text = re.sub(r'(\(?\d{3}\)?[\s.-]?\d{3}[\s.-]?\d{4})', ' ', text)
    text = re.sub(r'ext\.?\s?\d+', ' ', text)

    # Replace currency symbols
    text = re.sub(r'[\$€£₹¥]', ' <CURRENCY> ', text)
    text = re.sub(r'\b(?:usd|eur|gbp|inr|yen)\b', ' <CURRENCY> ', text, flags=re.IGNORECASE)

    # Replace numbers
    text = re.sub(r'\b\d+(?:[.,]\d+)?\b', ' <NUMBER> ', text)

    # Remove emoji (or keep if using emoji embeddings)
    text = ''.join([ch if ch not in emoji.EMOJI_DATA else ' <EMOJI> ' for ch in text])

    # Remove forwarded lines / metadata
    text = re.sub(r'(-{2,}|forwarded by|subject:.|from:.|to:.|cc:.|original message|unsubscribe.|trouble\? contact.)', ' ', text, flags=re.IGNORECASE)

    # Remove long sequences of dashes or underscores
    text = re.sub(r'[-_]{2,}', ' ', text)

    # Remove non-ASCII characters
    text = text.encode('ascii', errors='ignore').decode()

    # Remove tables or repeated pipe structures
    text = re.sub(r'\|.*?\|', ' ', text)
    # text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\n\s*\|', ' ', text)

    # Remove excessive punctuation or long token bursts
    text = re.sub(r'[^\w\s<>\']', ' ', text)
    text = re.sub(r'([!?.])\1{2,}', ' ', text)

    text = re.sub(r'\b[a-z]{1,2}\b','',text)

    # Collapse whitespace
    text = re.sub(r'\s+', ' ', text).strip()

    return text.strip()

def vectorize_features(feature_dict):
    """
    Convert feature dictionary to numpy vector or DataFrame row.
    """
    return pd.DataFrame([feature_dict])


def process_email(email_text):
    """
    Complete pipeline: takes raw email → returns cleaned text and features.
    """
    email_text = str(email_text) if not isinstance(email_text, str) else email_text
    cleaned_text = prepare_clean_text_for_embedding(email_text)
    features = extract_handcrafted_features(email_text)
    feature_vector = vectorize_features(features)
    return cleaned_text, feature_vector

def create_clean_and_featured_df(df, email_col='raw_email'):
  df = df.reset_index(drop=True)  # Ensure clean index
  df.dropna(subset=[email_col], inplace=True)
  cleaned_texts = []
  feature_vectors = []

  for text in df[email_col]:

    # Handle non-string values gracefully
    if not isinstance(text, str):
        text = ""

    # Cleaned email for embedding
    cleaned = prepare_clean_text_for_embedding(text)
    cleaned_texts.append(cleaned)

    # Extract features
    features_dict = extract_handcrafted_features(text)
    feature_df = vectorize_features(features_dict)

    # Extract the row from feature_df (assumes single row)
    feature_vectors.append(feature_df.iloc[0])

  # Add cleaned text
  df['cleaned_text'] = cleaned_texts

  # Build feature DataFrame and reset index
  features_combined_df = pd.DataFrame(feature_vectors).reset_index(drop=True)

  # Combine with main DataFrame
  df_final = pd.concat([df.reset_index(drop=True), features_combined_df], axis=1)

  return df_final

spamAssassin_data_final = create_clean_and_featured_df(spamAssassin_data, 'message')
spamAssassin_data_final.head(2)

spamAssassin_data_final.to_csv('spamAssassin_data_final.csv', index=False)

spamAssassin_data_final = pd.read_csv('spamAssassin_data_final.csv')

enron_data_final = create_clean_and_featured_df(enron_data, 'message')
enron_data_final.head(2)

enron_data_final.to_csv('enron_data_final.csv', index=False)

enron_data_final = pd.read_csv('enron_data_final.csv')

"""## Logistic Regression with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

# Define pipeline with bi-gram TF-IDF vectorizer, chi2 selector, and classifier
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        ngram_range=(2, 2)  # Use only bi-grams
    )),
    ('chi2', SelectKBest(score_func=chi2)),
    ('clf', LogisticRegression(
        solver='liblinear',
        max_iter=1000,
        class_weight='balanced'
    ))
])

# Define parameter grid
param_grid = {
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__ngram_range': [(1,1),(1,2),(2, 2)],
    'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000, 10000],
    'chi2__k': [100, 200, 500, 1000,3000,5000]
}

# Define stratified cross-validation and F1 scorer
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Perform grid search with cross-validation
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model to training data,
grid_search.fit(X_train, y_train)

# Print best parameters and F1 score
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Save best model and full grid search results
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_bigrams_LG.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_bigrams_LG.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_bigrams_LG.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

# Define pipeline with bi-gram TF-IDF vectorizer, chi2 selector, and classifier
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        ngram_range=(2, 2)  # Use only bi-grams
    )),
    ('chi2', SelectKBest(score_func=chi2)),
    ('clf', LogisticRegression(
        solver='liblinear',
        max_iter=1000,
        class_weight='balanced'
    ))
])

# Define parameter grid
param_grid = {
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__ngram_range': [(1,1),(1,2),(2, 2)],
    'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000, 10000],
    'chi2__k': [100, 200, 500, 1000,3000,5000]
}

# Define stratified cross-validation and F1 scorer
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Perform grid search with cross-validation
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model to training data
grid_search.fit(X_train, y_train)

# Print best parameters and F1 score
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Save best model and full grid search results
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_bigrams_LG.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_bigrams_LG.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_bigrams_LG.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Logistic Regression with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

# Simple selector for handcrafted columns
class FeatureSelector(BaseEstimator, TransformerMixin):
    def __init__(self, keys):
        self.keys = keys

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.keys].values

# Define handcrafted feature columns
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()

# Pipeline for handcrafted features only
pipeline = Pipeline([
    ('selector', FeatureSelector(feature_cols)),
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(solver='liblinear', max_iter=1000, class_weight='balanced'))
])

# Parameter grid for logistic regression
param_grid = {
    'clf__C': [0.01, 0.1, 1.0, 10.0]
}

# Cross-validation setup
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid search
grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=scorer, verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Output
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Save best model and full grid search results
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_features_LG.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_features_LG.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_features_LG.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

# Simple selector for handcrafted columns
class FeatureSelector(BaseEstimator, TransformerMixin):
    def __init__(self, keys):
        self.keys = keys

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.keys].values

# Define handcrafted feature columns
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()

# Pipeline for handcrafted features only
pipeline = Pipeline([
    ('selector', FeatureSelector(feature_cols)),
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(solver='liblinear', max_iter=1000, class_weight='balanced'))
])

# Parameter grid for logistic regression
param_grid = {
    'clf__C': [0.01, 0.1, 1.0, 10.0]
}

# Cross-validation setup
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid search
grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=scorer, verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Output
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Save best model and full grid search results
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_features_LG.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_features_LG.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_features_LG.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Naive Baye's with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score

# Pipeline: TF-IDF → Naive Bayes
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', MultinomialNB())
])

# Parameter grid
param_grid = {
     'tfidf__ngram_range': [(1, 1), (1, 2), (2,2)],
     'tfidf__min_df': [3],
     'tfidf__max_df': [0.95],
     'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000, 10000],
    #  'chi2__k': [100, 200, 500, 1000,3000,5000],
     'clf__alpha': [0.01, 0.1, 0.5, 1.0, 5.0]  # Smoothing parameter
}

# Scoring and cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Extract email text and labels
# X = trec_data_final['cleaned_text']
# y = trec_data_final['label']

# Grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)


# Fit
grid_search.fit(X_train, y_train)

# Results
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_bigrams_NB.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_bigrams_NB.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_bigrams_NB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score

# Pipeline: TF-IDF → Naive Bayes
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', MultinomialNB())
])
# Parameter grid
param_grid = {
     'tfidf__ngram_range': [(1, 1), (1, 2), (2,2)],
     'tfidf__min_df': [3],
     'tfidf__max_df': [0.95],
     'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000, 10000],
     'clf__alpha': [0.01, 0.1, 0.5, 1.0, 5.0]  # Smoothing parameter
}

# Scoring and cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)


# Grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)


# Fit
grid_search.fit(X_train, y_train)

# Results
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_bigrams_NB.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_bigrams_NB.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_bigrams_NB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Naive Baye's with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

# Define custom selector for handcrafted features
class FeatureSelector(BaseEstimator, TransformerMixin):
    def __init__(self, keys):
        self.keys = keys

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.keys].values

# Define handcrafted feature column names
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()

# Setup pipeline
pipeline = Pipeline([
    ('selector', FeatureSelector(feature_cols)),
    ('scale', StandardScaler(with_mean=False)),  # Naive Bayes can't handle negative values
    ('clf', MultinomialNB())
])

# Grid search parameters
param_grid = {
    'clf__alpha': [0.01, 0.1, 0.5, 1.0, 5.0]
}

# Setup cross-validation and scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# # Prepare data
# X = spamAssassin_data_final.drop(columns=['label'])  # OK to pass all columns because selector will pick only feature_cols
# y = spamAssassin_data_final['label']

# Perform grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit
grid_search.fit(X_train, y_train)

# Results
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

best_model = grid_search.best_estimator_

best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_features_NB.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_features_NB.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_features_NB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import make_scorer, f1_score
from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np

# Define custom selector for handcrafted features
class FeatureSelector(BaseEstimator, TransformerMixin):
    def __init__(self, keys):
        self.keys = keys

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.keys].values

# Define handcrafted feature column names
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()

# Setup pipeline
pipeline = Pipeline([
    ('selector', FeatureSelector(feature_cols)),
    ('scale', StandardScaler(with_mean=False)),  # Naive Bayes can't handle negative values
    ('clf', MultinomialNB())
])

# Grid search parameters
param_grid = {
    'clf__alpha': [0.01, 0.1, 0.5, 1.0, 5.0]
}

# Setup cross-validation and scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Prepare data
# X = enron_data_final.drop(columns=['label'])  # OK to pass all columns because selector will pick only feature_cols
# y = enron_data_final['label']

# Perform grid search
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit
grid_search.fit(X_train, y_train)

# Results
print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

best_model = grid_search.best_estimator_

best_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_features_NB.joblib")
joblib.dump(best_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_features_NB.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_features_NB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Support Vector Machine with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score


# Define the pipeline: TF-IDF vectorizer + Linear SVM
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', LinearSVC(
        class_weight='balanced',  # handles imbalance
        max_iter=10000            # ensures convergence
    ))
])

# Grid of parameters to search
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [1000, 5000, 10000, 20000],
    'clf__C': [0.1, 0.5, 1.0]  # regularization strength
}

# Set up cross-validation and scoring metric
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# GridSearchCV to find best parameters
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model after tuning
best_svm_model = grid_search.best_estimator_

best_svm_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_bigrams_SVM.joblib")
joblib.dump(best_svm_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_bigrams_SVM.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_bigrams_SVM.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score


# Define the pipeline: TF-IDF vectorizer + Linear SVM
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', LinearSVC(
        class_weight='balanced',  # handles imbalance
        max_iter=10000            # ensures convergence
    ))
])

# Grid of parameters to search
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [1000, 5000, 10000, 20000],
    'clf__C': [0.1, 0.5, 1.0]  # regularization strength
}

# Set up cross-validation and scoring metric
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# GridSearchCV to find best parameters
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model after tuning
best_svm_model = grid_search.best_estimator_

best_svm_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_bigrams_SVM.joblib")
joblib.dump(best_svm_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_bigrams_SVM.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_bigrams_SVM.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Support Vector Machine with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label','source','message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV

# Define handcrafted feature columns
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Standardize features + Linear SVM
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', LinearSVC(class_weight='balanced', max_iter=10000))
])

# Define grid of hyperparameters
param_grid = {
    'clf__C': [0.1, 1.0, 5.0]
}

# Stratified 5-fold CV
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best trained model
best_handcrafted_svm_model = grid_search.best_estimator_


best_handcrafted_svm_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "spam_assassin_features_SVM.joblib")
joblib.dump(best_svm_model, model_path)

model_path = os.path.join("Models", "gridsearch_spam_assassin_features_SVM.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','spam_assassin_features_SVM.joblib'))

y_pred = best_handcrafted_svm_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label','source','message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV

# Define handcrafted feature columns
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Standardize features + Linear SVM
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', LinearSVC(class_weight='balanced', max_iter=10000))
])

# Define grid of hyperparameters
param_grid = {
    'clf__C': [0.1, 1.0, 5.0]
}

# Stratified 5-fold CV
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best trained model
best_handcrafted_svm_model = grid_search.best_estimator_


best_handcrafted_svm_model.fit(X_train, y_train)

os.makedirs("Models", exist_ok=True)
# Define path to save the model
model_path = os.path.join("Models", "enron_features_SVM.joblib")
joblib.dump(best_svm_model, model_path)

model_path = os.path.join("Models", "gridsearch_enron_features_SVM.joblib")
joblib.dump(grid_search, model_path)

best_model = joblib.load(os.path.join('Models','enron_features_SVM.joblib'))

y_pred = best_handcrafted_svm_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Decision Tree with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define the pipeline: TF-IDF vectorizer + Decision Tree
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
])

# Define grid of hyperparameters for tuning
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [5000, 7500, 10000, 20000],
    'clf__max_depth': [20, 50, None],
    'clf__min_samples_split': [2],
    'clf__min_samples_leaf': [2]
}

# Define cross-validation and scorer
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Store the best model
best_dt_model = grid_search.best_estimator_
best_dt_model.fit(X_train, y_train)

joblib.dump(best_dt_model, os.path.join('Models','spam_assassin_bigrams_DT.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_DT.joblib'))

best_model = joblib.load(os.path.join('Models','spam_assassin_bigrams_DT.joblib'))

y_pred = best_dt_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define the pipeline: TF-IDF vectorizer + Decision Tree
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
])

# Define grid of hyperparameters for tuning
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [5000, 7500, 10000, 20000],
    'clf__max_depth': [20, 50, None],
    'clf__min_samples_split': [2],
    'clf__min_samples_leaf': [2]
}

# Define cross-validation and scorer
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Store the best model
best_dt_model = grid_search.best_estimator_
best_dt_model.fit(X_train, y_train)

joblib.dump(best_dt_model, os.path.join('Models','enron_bigrams_DT.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_DT.joblib'))

best_model = joblib.load(os.path.join('Models','enron_bigrams_DT.joblib'))

y_pred = best_dt_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Decision Tree with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label','source','message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define handcrafted feature columns
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: StandardScaler + Decision Tree Classifier
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
])

# Define hyperparameter grid for tuning
param_grid = {
    'clf__max_depth': [5, 10, 20, 50, None],
    'clf__min_samples_split': [2, 5, 10],
    'clf__min_samples_leaf': [1, 2, 5]
}

# Stratified 5-fold cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best decision tree model
best_handcrafted_dt_model = grid_search.best_estimator_
best_handcrafted_dt_model.fit(X_train, y_train)

joblib.dump(best_handcrafted_dt_model, os.path.join('Models','spam_assassin_features_features_DT.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_features_features_DT.joblib'))

best_model = joblib.load(os.path.join('Models','spam_assassin_features_features_DT.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label','source','message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define handcrafted feature columns
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: StandardScaler + Decision Tree Classifier
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))
])

# Define hyperparameter grid for tuning
param_grid = {
    'clf__max_depth': [5, 10, 20, 50, None],
    'clf__min_samples_split': [2, 5, 10],
    'clf__min_samples_leaf': [1, 2, 5]
}

# Stratified 5-fold cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best decision tree model
best_handcrafted_dt_model = grid_search.best_estimator_
best_handcrafted_dt_model.fit(X_train, y_train)

joblib.dump(best_handcrafted_dt_model, os.path.join('Models','enron_features_features_DT.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_enron_features_features_DT.joblib'))

best_model = joblib.load(os.path.join('Models','enron_features_features_DT.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Random Forest with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score


# Define pipeline: TF-IDF + Random Forest Classifier
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))
])

# Define parameter grid for GridSearchCV
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [5000, 10000, 20000],
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [20, 50],
    'clf__min_samples_split': [2, 5],
    'clf__min_samples_leaf': [1, 2]
}

# Set up cross-validation and F1 scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best trained model
best_rf_model = grid_search.best_estimator_
best_rf_model.fit(X_train, y_train)

joblib.dump(best_rf_model, os.path.join('Models','spam_assassin_bigrams_RF.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_bigrams_RF.joblib'))

best_model = joblib.load(os.path.join('Models','spam_assassin_bigrams_RF.joblib'))

y_pred = best_rf_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset

"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score


# Define pipeline: TF-IDF + Random Forest Classifier
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))
])

# Define parameter grid for GridSearchCV
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [3],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [5000, 10000, 20000],
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [20, 50],
    'clf__min_samples_split': [2, 5],
    'clf__min_samples_leaf': [1, 2]
}

# Set up cross-validation and F1 scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output best results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best trained model
best_rf_model = grid_search.best_estimator_
best_rf_model.fit(X_train, y_train)

joblib.dump(best_rf_model, os.path.join('Models','enron_bigrams_RF.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_enron_bigrams_RF.joblib'))

best_model = joblib.load(os.path.join('Models','enron_bigrams_RF.joblib'))

y_pred = best_rf_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Random Forest with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label','source','message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Select only handcrafted feature columns
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Scaling + Random Forest
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))
])

# Define parameter grid
param_grid = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [10, 20, 50],
    'clf__min_samples_split': [2],
    'clf__min_samples_leaf': [2]
}

# CV setup
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid Search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_rf_handcrafted_model = grid_search.best_estimator_
best_rf_handcrafted_model.fit(X_train, y_train)

import os
import joblib
joblib.dump(best_rf_handcrafted_model, os.path.join('Models','spam_assassin_features_RF.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_features_RF.joblib'))

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
best_model = joblib.load(os.path.join('Models','spam_assassin_features_RF.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label','source','message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Select only handcrafted feature columns
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Scaling + Random Forest
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))
])

# Define parameter grid
param_grid = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [10, 20, 50],
    'clf__min_samples_split': [2],
    'clf__min_samples_leaf': [2]
}

# CV setup
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid Search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_rf_handcrafted_model = grid_search.best_estimator_
best_rf_handcrafted_model.fit(X_train, y_train)

import os
import joblib
joblib.dump(best_rf_handcrafted_model, os.path.join('Models','enron_features_RF.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_enron_features_RF.joblib'))

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
best_model = joblib.load(os.path.join('Models','enron_features_RF.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## XG Boost with N-grams

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split
cleaned_text = spamAssassin_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define pipeline: TF-IDF + XGBoost
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        objective='binary:logistic',
        n_jobs=2,
        random_state=42,
        scale_pos_weight=1  # adjust manually if strong imbalance
    ))
])

# Grid of hyperparameters
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [2],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [1000, 3000, 5000],
    'clf__n_estimators': [200],
    'clf__max_depth': [10],
    'clf__learning_rate': [0.1],
    'clf__subsample': [0.8],
    'clf__colsample_bytree': [0.8]
}

# Stratified cross-validation
cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_xgb_model = grid_search.best_estimator_
best_xgb_model.fit(X_train, y_train)

import os
import joblib
joblib.dump(best_xgb_model, os.path.join('Models','spam_assassin_XGB3.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_XGB3.joblib'))

best_model = joblib.load(os.path.join('Models','spam_assassin_XGB3.joblib'))

y_pred = best_xgb_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split
cleaned_text = enron_data_final['cleaned_text'].fillna("").astype(str)

X_train, X_test, y_train, y_test = train_test_split(
    cleaned_text, enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Define pipeline: TF-IDF + XGBoost
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(
        token_pattern=r'<[^>]+>|\b\w+\b',
        lowercase=True,
        stop_words='english'
    )),
    ('clf', XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        objective='binary:logistic',
        n_jobs=2,
        random_state=42,
        scale_pos_weight=1  # adjust manually if strong imbalance
    ))
])

# Grid of hyperparameters
param_grid = {
    'tfidf__ngram_range': [(1, 1), (2, 2)],
    'tfidf__min_df': [2],
    'tfidf__max_df': [0.95],
    'tfidf__max_features': [1000, 3000, 5000],
    'clf__n_estimators': [200],
    'clf__max_depth': [10],
    'clf__learning_rate': [0.1],
    'clf__subsample': [0.8],
    'clf__colsample_bytree': [0.8]
}

# Stratified cross-validation
cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Run GridSearchCV
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=-1
)

# Fit the model
grid_search.fit(X_train, y_train)

# Output results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_xgb_model = grid_search.best_estimator_
best_xgb_model.fit(X_train, y_train)

import os
import joblib
joblib.dump(best_xgb_model, os.path.join('Models','enron_XGB3.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_enron_XGB3.joblib'))

best_model = joblib.load(os.path.join('Models','enron_XGB3.joblib'))

y_pred = best_xgb_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## XG Boost with only Handcrafted Features

## Spam Assassin Dataset
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    spamAssassin_data_final.drop(columns=['cleaned_text', 'label','source','message']), spamAssassin_data_final['label'], test_size=0.2, stratify=spamAssassin_data_final['label'], random_state=42
)

from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Select handcrafted feature columns
feature_cols = spamAssassin_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Standardize + XGBoost
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        objective='binary:logistic',
        n_jobs=2,  # Limit for memory safety
        random_state=42,
        scale_pos_weight=1  # Adjust based on class balance if needed
    ))
])

# Grid of hyperparameters (kept tight to avoid memory issues)
param_grid = {
    'clf__n_estimators': [200],
    'clf__max_depth': [3, 6, 10],
    'clf__learning_rate': [0.1, 0.2],
    'clf__subsample': [0.8],
    'clf__colsample_bytree': [0.8]
}

# Define cross-validation and scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=2  # Be cautious with memory
)

# Fit the model
grid_search.fit(X_train, y_train)

# Print results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_xgb_handcrafted_model = grid_search.best_estimator_
best_xgb_handcrafted_model.fit(X_train, y_train)

joblib.dump(best_xgb_handcrafted_model, os.path.join('Models','spam_assassin_features_XGB.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_spam_assassin_features_XGB.joblib'))

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
best_model = joblib.load(os.path.join('Models','spam_assassin_features_XGB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Enron Dataset"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    enron_data_final.drop(columns=['cleaned_text', 'label','source','message']), enron_data_final['label'], test_size=0.2, stratify=enron_data_final['label'], random_state=42
)

from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score

# Select handcrafted feature columns
feature_cols = enron_data_final.drop(columns=['cleaned_text', 'label', 'source', 'message']).columns.tolist()


# Define pipeline: Standardize + XGBoost
pipeline = Pipeline([
    ('scale', StandardScaler()),
    ('clf', XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        objective='binary:logistic',
        n_jobs=2,  # Limit for memory safety
        random_state=42,
        scale_pos_weight=1  # Adjust based on class balance if needed
    ))
])

# Grid of hyperparameters (kept tight to avoid memory issues)
param_grid = {
    'clf__n_estimators': [200],
    'clf__max_depth': [3, 6, 10],
    'clf__learning_rate': [0.1, 0.2],
    'clf__subsample': [0.8],
    'clf__colsample_bytree': [0.8]
}

# Define cross-validation and scoring
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scorer = make_scorer(f1_score)

# Grid search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=cv,
    scoring=scorer,
    verbose=1,
    n_jobs=2  # Be cautious with memory
)

# Fit the model
grid_search.fit(X_train, y_train)

# Print results
print("Best Parameters:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

# Best model
best_xgb_handcrafted_model = grid_search.best_estimator_
best_xgb_handcrafted_model.fit(X_train, y_train)

joblib.dump(best_xgb_handcrafted_model, os.path.join('Models','enron_features_XGB.joblib'))
joblib.dump(grid_search, os.path.join('Models','gridsearch_enron_features_XGB.joblib'))

from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
best_model = joblib.load(os.path.join('Models','enron_features_XGB.joblib'))

y_pred = best_model.predict(X_test)

precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')

"""## Exploratory Data Analysis

## F1 Score Comparison
"""

import matplotlib.pyplot as plt
import matplotlib.animation as animation
import numpy as np

# Data
model_names = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Decision Tree', 'Random Forest', 'XGBoost']
TREC = [0.992, 0.983, 0.995, 0.988, 0.994, 0.991]
Enron = [0.98, 0.98, 0.988, 0.952, 0.975, 0.978]
Spam_Assassin = [0.969, 0.972, 0.994, 0.967, 0.982, 0.994]

# Prepare data for animation
datasets = ['TREC', 'Enron', 'Spam Assassin']
data = [TREC, Enron, Spam_Assassin]
colors = ['#FF5733', '#33FF57', '#3357FF']  # Colors for each dataset

# Set up the figure and axis
fig, ax = plt.subplots(figsize=(12, 6))
ax.set_xlim(-0.5, len(model_names) - 0.5)
ax.set_ylim(0.9, 1.0)  # Adjust y-axis limits based on F1 scores
ax.set_title("F1 Score Comparison Across Models (N-grams)", fontsize=16, fontweight='bold')
ax.set_xlabel("Models", fontsize=14)
ax.set_ylabel("F1 Score", fontsize=14)
ax.set_xticks(range(len(model_names)))
ax.set_xticklabels(model_names, rotation=45, ha='right')
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Initialize empty lines for animation
lines = [ax.plot([], [], label=dataset, color=color, marker='o', lw=2)[0] for dataset, color in zip(datasets, colors)]

# Move the legend to the right side, vertically stacked
legend = ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), fancybox=True, shadow=True, fontsize=12)
plt.tight_layout(rect=[0, 0, 0.8, 1])  # Adjust layout to make space for the legend

# Animation update function
def animate(frame):
    for i, line in enumerate(lines):
        line.set_data(range(frame + 1), data[i][:frame + 1])  # Update x and y data
    return lines

# Create animation
ani = animation.FuncAnimation(fig, animate, frames=len(model_names), interval=1000, blit=True)

# Save or display the animation
plt.tight_layout()

# For Jupyter Notebook: Enable interactive mode
try:
    from IPython.display import HTML
    HTML(ani.to_jshtml())  # Display animation in Jupyter Notebook
except:
    pass

plt.show()

# To save the animation as a GIF (optional):
# ani.save('animated_line_chart.gif', writer='imagemagick', fps=2)

import matplotlib.pyplot as plt
import matplotlib.animation as animation
import numpy as np

# Data
model_names = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Decision Tree', 'Random Forest', 'XGBoost']
TREC = [0.752, 0.813, 0.758, 0.904, 0.907, 0.918]
Enron = [0.546, 0.672, 0.54, 0.594, 0.592, 0.615]
Spam_Assassin = [0.562, 0.3, 0.542, 0.869, 0.84, 0.865]

# Prepare data for animation
datasets = ['TREC', 'Enron', 'Spam Assassin']
data = [TREC, Enron, Spam_Assassin]
colors = ['#FF5733', '#33FF57', '#3357FF']  # Colors for each dataset

# Set up the figure and axis
fig, ax = plt.subplots(figsize=(12, 6))
ax.set_xlim(-0.5, len(model_names) - 0.5)
ax.set_ylim(0, 1.0)  # Adjust y-axis limits based on F1 scores
ax.set_title("F1 Score Comparison Across Models (Features)", fontsize=16, fontweight='bold')
ax.set_xlabel("Models", fontsize=14)
ax.set_ylabel("F1 Score", fontsize=14)
ax.set_xticks(range(len(model_names)))
ax.set_xticklabels(model_names, rotation=45, ha='right')
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Initialize empty lines for animation
lines = [ax.plot([], [], label=dataset, color=color, marker='o', lw=2)[0] for dataset, color in zip(datasets, colors)]

# Move the legend to the right side, vertically stacked
legend = ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), fancybox=True, shadow=True, fontsize=12)
plt.tight_layout(rect=[0, 0, 0.8, 1])  # Adjust layout to make space for the legend

# Animation update function
def animate(frame):
    for i, line in enumerate(lines):
        line.set_data(range(frame + 1), data[i][:frame + 1])  # Update x and y data
    return lines

# Create animation
ani = animation.FuncAnimation(fig, animate, frames=len(model_names), interval=1000, blit=True)

# Save or display the animation
plt.tight_layout()

# For Jupyter Notebook: Enable interactive mode
try:
    from IPython.display import HTML
    HTML(ani.to_jshtml())  # Display animation in Jupyter Notebook
except:
    pass

plt.show()

"""## Confusion Matrix for Best Model (N-grams)

## Spam Assassin - XGBoost
"""

import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

model = joblib.load(os.path.join('Models','spam_assassin_XGB3.joblib'))

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Step 5: Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.show()

"""## Enron - SVM"""

import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

model = joblib.load(os.path.join('Models','enron_bigrams_SVM.joblib'))

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Step 5: Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.show()

"""## Confusion Matrix for Best Model (Features)

## Spam Assassin - Decision Tree
"""

import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

model = joblib.load(os.path.join('Models','spam_assassin_features_features_DT.joblib'))

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Step 5: Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.show()

"""## Enron - Naive Baye's"""

import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

model = joblib.load(os.path.join('Models','enron_features_NB.joblib'))

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Step 5: Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.show()

"""## Enron - XG Boost"""

import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

model = joblib.load(os.path.join('Models','enron_features_XGB.joblib'))

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Step 5: Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
plt.xlabel('Predicted Labels', fontsize=14)
plt.ylabel('True Labels', fontsize=14)
plt.show()



